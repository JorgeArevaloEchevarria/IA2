{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpd0gkGnpzXT"
   },
   "source": [
    "# Práctica 2: Procesamiento del Lenguaje Natural\n",
    "\n",
    "__Fecha de entrega: 17 de abril de 2022__\n",
    "\n",
    "El objetivo de esta práctica es aplicar los conceptos teóricos vistos en clase en el módulo de PLN. La práctica consta de 2 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n",
    "\n",
    "Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n",
    "\n",
    "Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBx1oG6bpzXY"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkJPtLPRpzXa"
   },
   "source": [
    "# Apartado 2: Recuperación de información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWQ9sB-ApzXc"
   },
   "source": [
    "Número de grupo: 02\n",
    "\n",
    "Nombres de los estudiantes: Jesus Martin y Jorge Arevalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1iFIS_EpzXc"
   },
   "source": [
    "## 1) Carga del conjunto de datos\n",
    "\n",
    "El fichero `BBC News.csv` contiene noticias clasificadas en 5 categorías diferentes. \n",
    "\n",
    "Carga los datos en un dataframe teniendo en cuenta que la columna `ArticleId` es un identificador de la noticia y por lo tanto no lo vamos a usar. \n",
    "\n",
    "Estudia el tamaño del conjunto de datos y la proporción de noticias que pertenecen a cada una de las categorías.\n",
    "\n",
    "Crea una partición estratificada de los datos dejando el 80% para entrenamiento y el 20% restante para test usando la función `train_test_split` de sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufbBvGcnpzXe"
   },
   "outputs": [],
   "source": [
    "#Todos los Imports necesarios\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = np.ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data:\n",
    "        print('Mensaje', index, ':', data[index])\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"BBC News.csv\")\n",
    "print(df)\n",
    "#eliminamos la columna ArticleId para clasificar\n",
    "df = df.drop(['ArticleId'], axis=1)\n",
    "print(df)\n",
    "\n",
    "#Creamos una partición de los datos dejando el 80% para entrenamiento y el 20% restante para test \n",
    "from sklearn.model_selection import train_test_split\n",
    "#train_data, test_data = train_test_split(df, test_size=0.2)\n",
    "train_data, test_data, train_category, test_category  = train_test_split(df['Text'], df['Category'], test_size = 0.2)\n",
    "\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print(\"Training texts:\", len(train_data.data))\n",
    "print(\"Test texts:\", len(test_data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Fx5hJC7pzXf"
   },
   "source": [
    "## 2) Representación basada en bolsa de palabras y tf-idf\n",
    "\n",
    "La primera vectorización que vamos a usar representará los mensajes usando el modelo de bolsa de palabras, monogramas y el valor tf-idf de cada palabra. Usa como _stop words_ las que vienen configuradas por defecto para el inglés.\n",
    "\n",
    "Aplica la vectorización a los conjuntos de mensajes de entrenamiento y test. Muestra algún mensaje tanto en su formato de texto original como en la versión vectorizada. ¿Qué palabras se han eliminado y por qué?\n",
    "\n",
    "Calcula la precisión@5 de cada una de las clases usando como consultas los documentos de la partición de test y la similitud del coseno. Vamos a considerar que un documento recuperado es relevante cuando pertenezca a la misma clase que la consulta.\n",
    "\n",
    "Dibuja los resultados en un diagrama de barras y comenta las clases en las que se comporta mejor y peor. ¿Crees que los resultados son buenos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKdL2-VSpzXg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH7sldldpzXi"
   },
   "source": [
    "## 3) Representación basada en word-embeddings y tf-idf\n",
    "\n",
    "La segunda vectorización que vamos a usar representará los mensajes usando usando word-embeddings usando como los pesos tf-idf de cada palabra. Al igual que en el apartado anterior, usaremos monogramas y las _stop words_ que vienen configuradas por defecto para el inglés. Recuerda usar como vocabulario para vectorizar el vocabulario del fichero con las word-embeddings.\n",
    "\n",
    "Aplica la vectorización a los conjuntos de mensajes de entrenamiento y test.\n",
    "\n",
    "Calcula la precisión@5 de cada una de las clases usando como consultas los documentos de la partición de test y la similitud del coseno. Vamos a considerar que un documento recuperado es relevante cuando pertenezca a la misma clase que la consulta.\n",
    "\n",
    "Dibuja los resultados en un diagrama de barras y compara los resultados con los del apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-J6GYut4DGu"
   },
   "source": [
    "## 4) Análisis de errores\n",
    "\n",
    "Vamos a investigar los resultados para entender mejor dónde están fallando los procesos de recuperación. Sigue los siguientes pasos.\n",
    "\n",
    "\n",
    "1. Identifica la categoría de noticias donde la precisión media haya mejorado más al incorporar word-embeddings\n",
    "2. Para dicha categoría, identifica la consulta donde la precisión haya mejorado más al usar word-embeddings\n",
    "3. Muestra el texto original de la consulta y los términos que aparecen en las dos vectorizaciones tf-idf que usamos (recuerda que usamos diccionarios distintos para las vectorizaciones bolsa de palabras y word-embeddings).\n",
    "4. Identifica las noticias recuperadas para dicha consulta para las dos aproximaciones y sus categorías (TF-IDF puro y con word-embeddings)\n",
    "5. Muestra la intersección de términos entre la consulta y la primera noticia mal recuperada usando TF-IDF puro.\n",
    "6. Muestra la intersección de términos entre la consulta y la última noticia bien recuperada usando word-embeddings.\n",
    "7. A la luz de todo lo anterior, razona sobre por qué crees que el TF-IDF no fue capaz de clasificar bien la noticia y el word-embedding sí.\n",
    "\n",
    "\n",
    "Puedes usar el código que calcula la intersección de términos que ponemos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUat8DCRLYs1"
   },
   "outputs": [],
   "source": [
    "def terms_in_message(feature_names,vector_data,index):\n",
    "    '''\n",
    "    Devuelve un conjunto los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    mensaje=vector_data[index,:]>0\n",
    "    terminos_presentes = ma.array(feature_names, mask = ~(mensaje[0].toarray()))\n",
    "\n",
    "    return set(terminos_presentes.compressed())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "P2_recuperacion_informacion_2122_enunciado.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
